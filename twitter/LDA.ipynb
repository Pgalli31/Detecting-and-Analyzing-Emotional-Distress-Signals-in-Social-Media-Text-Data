{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e263d54-9493-4807-8dc8-fcd2bd28af98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[nltk_data] Downloading package wordnet to /Users/pgalli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pgalli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "from nltk.corpus import stopwords\n",
    "import en_core_web_md\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b12165e-8d7f-4c62-844c-ad849ef1f348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('twitter_data_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3fd4fd-8bb9-49e5-ab8c-fbd0a60c33ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load(disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ']):\n",
    "    '''This function converts terms to their base forms.'''\n",
    "    output = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(str(sent))\n",
    "        output.append(\n",
    "            [token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return output\n",
    "\n",
    "\n",
    "text_list = data['clean_post'].tolist()\n",
    "tokenized_text = lemmatization(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e8d280-0bb2-47e6-bb0f-3c879bae3d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_text)\n",
    "if len(dictionary) > 0:\n",
    "    doc_term_matrix = [dictionary.doc2bow(text) for text in tokenized_text]\n",
    "else:\n",
    "    doc_term_matrix = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77995f4-8ff0-49c6-be06-b5969638a071",
   "metadata": {},
   "source": [
    "## 10 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98cc4ae5-9fd0-444c-a021-f7411f61ad7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.057*\"year\" + 0.049*\"day\" + 0.032*\"today\" + 0.017*\"old\" + 0.016*\"name\" + 0.014*\"hour\" + 0.014*\"nice\" + 0.013*\"lot\" + 0.013*\"talk\" + 0.012*\"stupid\"'), (1, '0.079*\"thank\" + 0.034*\"happy\" + 0.028*\"much\" + 0.021*\"right\" + 0.018*\"week\" + 0.014*\"cool\" + 0.013*\"birthday\" + 0.012*\"little\" + 0.012*\"gopayt\" + 0.012*\"strong\"'), (2, '0.039*\"award\" + 0.018*\"tonight\" + 0.016*\"word\" + 0.016*\"ill\" + 0.014*\"season\" + 0.012*\"part\" + 0.012*\"show\" + 0.011*\"sad\" + 0.011*\"dream\" + 0.011*\"change\"'), (3, '0.042*\"twitter\" + 0.028*\"u\" + 0.015*\"one\" + 0.014*\"business\" + 0.014*\"least\" + 0.012*\"bed\" + 0.012*\"dad\" + 0.011*\"hope\" + 0.010*\"brain\" + 0.010*\"sweet\"'), (4, '0.050*\"heart\" + 0.047*\"depression\" + 0.027*\"real\" + 0.018*\"vote\" + 0.016*\"kid\" + 0.014*\"mom\" + 0.013*\"movie\" + 0.011*\"light\" + 0.011*\"care\" + 0.009*\"free\"'), (5, '0.022*\"trump\" + 0.019*\"family\" + 0.019*\"night\" + 0.017*\"return\" + 0.016*\"last\" + 0.016*\"morning\" + 0.013*\"sleep\" + 0.013*\"pbb\" + 0.013*\"problem\" + 0.012*\"home\"'), (6, '0.086*\"people\" + 0.033*\"way\" + 0.032*\"guy\" + 0.029*\"pillow\" + 0.027*\"foryong\" + 0.020*\"work\" + 0.019*\"world\" + 0.013*\"tilltheend\" + 0.011*\"first\" + 0.011*\"child\"'), (7, '0.055*\"life\" + 0.053*\"man\" + 0.031*\"girl\" + 0.017*\"money\" + 0.016*\"baby\" + 0.014*\"hair\" + 0.013*\"month\" + 0.012*\"job\" + 0.011*\"white\" + 0.011*\"high\"'), (8, '0.118*\"good\" + 0.053*\"time\" + 0.044*\"thing\" + 0.043*\"new\" + 0.025*\"bad\" + 0.020*\"person\" + 0.017*\"big\" + 0.015*\"amp\" + 0.013*\"sure\" + 0.010*\"migraine\"'), (9, '0.057*\"video\" + 0.039*\"music\" + 0.036*\"love\" + 0.033*\"friend\" + 0.024*\"great\" + 0.020*\"game\" + 0.020*\"fuck\" + 0.019*\"tweet\" + 0.017*\"shit\" + 0.015*\"well\"')]\n"
     ]
    }
   ],
   "source": [
    "if doc_term_matrix:\n",
    "    LDA = gensim.models.ldamodel.LdaModel\n",
    "    lda_model = LDA(\n",
    "        corpus=doc_term_matrix,\n",
    "        id2word=dictionary,\n",
    "        num_topics=10,\n",
    "        random_state=100,\n",
    "        chunksize=1000,\n",
    "        passes=50,\n",
    "        iterations=100\n",
    "    )\n",
    "    print(lda_model.print_topics())\n",
    "else:\n",
    "    print(\"Document term matrix is empty, cannot build LDA model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fef79d5-768d-4542-8077-83aadd7acd42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity: -10.208149988491838\n",
      "Coherence: 0.5353578244090614\n"
     ]
    }
   ],
   "source": [
    "total_docs = len(doc_term_matrix)\n",
    "if total_docs > 0:\n",
    "    print('\\nPerplexity:', lda_model.log_perplexity(\n",
    "        doc_term_matrix, total_docs=total_docs))\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model,\n",
    "        texts=tokenized_text,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence:', coherence_lda)\n",
    "else:\n",
    "    print(\"No documents to evaluate coherence or perplexity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e4cca8a-bc49-4a6b-8761-b335ea58bfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if total_docs > 0:\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis_data = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "    vis_data\n",
    "    pyLDAvis.save_html(vis_data, '10_twitter_lda_visualization.html')\n",
    "else:\n",
    "    print(\"No documents for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6ef35-8f3b-4f67-beac-60b5af13e62e",
   "metadata": {},
   "source": [
    "## 20 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ddbc4e-8e70-47b8-865e-2693ca49c8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.070*\"week\" + 0.052*\"sleep\" + 0.051*\"woman\" + 0.041*\"second\" + 0.041*\"law\" + 0.027*\"office\" + 0.027*\"death\" + 0.021*\"awesome\" + 0.016*\"disorder\" + 0.013*\"sign\"'), (1, '0.155*\"friend\" + 0.062*\"nice\" + 0.041*\"idea\" + 0.035*\"school\" + 0.035*\"rt\" + 0.029*\"bitch\" + 0.022*\"self\" + 0.019*\"autism\" + 0.014*\"american\" + 0.013*\"option\"'), (2, '0.169*\"thing\" + 0.064*\"big\" + 0.037*\"part\" + 0.034*\"business\" + 0.028*\"top\" + 0.027*\"eye\" + 0.022*\"war\" + 0.020*\"easy\" + 0.019*\"side\" + 0.017*\"list\"'), (3, '0.064*\"well\" + 0.051*\"ill\" + 0.039*\"question\" + 0.037*\"point\" + 0.036*\"funny\" + 0.034*\"help\" + 0.033*\"story\" + 0.030*\"place\" + 0.026*\"line\" + 0.022*\"sale\"'), (4, '0.062*\"baby\" + 0.046*\"mind\" + 0.040*\"boy\" + 0.039*\"fan\" + 0.038*\"door\" + 0.033*\"head\" + 0.023*\"difference\" + 0.019*\"style\" + 0.019*\"suicide\" + 0.017*\"less\"'), (5, '0.088*\"fuck\" + 0.076*\"shit\" + 0.041*\"one\" + 0.031*\"bed\" + 0.024*\"tired\" + 0.024*\"anxiety\" + 0.020*\"skin\" + 0.019*\"happiness\" + 0.018*\"post\" + 0.017*\"election\"'), (6, '0.133*\"way\" + 0.077*\"first\" + 0.050*\"cool\" + 0.027*\"worth\" + 0.026*\"group\" + 0.026*\"thought\" + 0.018*\"entire\" + 0.018*\"pretty\" + 0.017*\"green\" + 0.016*\"party\"'), (7, '0.145*\"man\" + 0.089*\"bad\" + 0.032*\"service\" + 0.030*\"care\" + 0.030*\"high\" + 0.025*\"hope\" + 0.024*\"call\" + 0.023*\"important\" + 0.022*\"lie\" + 0.020*\"type\"'), (8, '0.165*\"time\" + 0.069*\"work\" + 0.048*\"next\" + 0.033*\"birthday\" + 0.031*\"month\" + 0.030*\"strong\" + 0.026*\"least\" + 0.025*\"book\" + 0.025*\"positive\" + 0.024*\"car\"'), (9, '0.198*\"people\" + 0.164*\"thank\" + 0.050*\"many\" + 0.042*\"old\" + 0.027*\"problem\" + 0.021*\"beautiful\" + 0.021*\"amazing\" + 0.019*\"team\" + 0.018*\"reason\" + 0.017*\"low\"'), (10, '0.076*\"amp\" + 0.046*\"mental\" + 0.039*\"parent\" + 0.035*\"food\" + 0.031*\"favorite\" + 0.020*\"mood\" + 0.016*\"illness\" + 0.016*\"figure\" + 0.014*\"smell\" + 0.013*\"smile\"'), (11, '0.147*\"year\" + 0.118*\"new\" + 0.058*\"real\" + 0.058*\"last\" + 0.039*\"tonight\" + 0.028*\"little\" + 0.025*\"fake\" + 0.020*\"free\" + 0.019*\"song\" + 0.017*\"human\"'), (12, '0.113*\"guy\" + 0.101*\"twitter\" + 0.049*\"lot\" + 0.035*\"sad\" + 0.035*\"dream\" + 0.028*\"different\" + 0.025*\"hand\" + 0.024*\"sweet\" + 0.023*\"need\" + 0.013*\"soul\"'), (13, '0.104*\"love\" + 0.079*\"happy\" + 0.067*\"girl\" + 0.057*\"person\" + 0.056*\"tweet\" + 0.034*\"tomorrow\" + 0.029*\"wrong\" + 0.027*\"home\" + 0.025*\"truth\" + 0.023*\"company\"'), (14, '0.050*\"health\" + 0.049*\"show\" + 0.048*\"light\" + 0.030*\"d\" + 0.030*\"tv\" + 0.028*\"safe\" + 0.025*\"glad\" + 0.025*\"relationship\" + 0.013*\"see\" + 0.013*\"blue\"'), (15, '0.122*\"depression\" + 0.069*\"game\" + 0.052*\"night\" + 0.047*\"return\" + 0.044*\"word\" + 0.036*\"hair\" + 0.030*\"change\" + 0.028*\"dead\" + 0.026*\"end\" + 0.019*\"adult\"'), (16, '0.250*\"good\" + 0.123*\"video\" + 0.089*\"life\" + 0.084*\"music\" + 0.048*\"much\" + 0.035*\"world\" + 0.027*\"kid\" + 0.020*\"job\" + 0.019*\"country\" + 0.014*\"final\"'), (17, '0.138*\"heart\" + 0.083*\"great\" + 0.047*\"hour\" + 0.037*\"black\" + 0.030*\"cat\" + 0.029*\"white\" + 0.021*\"smart\" + 0.020*\"animal\" + 0.020*\"proud\" + 0.019*\"sense\"'), (18, '0.158*\"day\" + 0.056*\"right\" + 0.052*\"family\" + 0.032*\"long\" + 0.032*\"true\" + 0.025*\"phone\" + 0.025*\"pain\" + 0.023*\"single\" + 0.022*\"lol\" + 0.021*\"dark\"'), (19, '0.135*\"today\" + 0.057*\"morning\" + 0.055*\"talk\" + 0.043*\"child\" + 0.032*\"body\" + 0.029*\"stuff\" + 0.028*\"enough\" + 0.023*\"whole\" + 0.022*\"support\" + 0.021*\"picture\"')]\n"
     ]
    }
   ],
   "source": [
    "if doc_term_matrix:\n",
    "    LDA = gensim.models.ldamodel.LdaModel\n",
    "    lda_model = LDA(\n",
    "        corpus=doc_term_matrix,\n",
    "        id2word=dictionary,\n",
    "        num_topics=20,\n",
    "        random_state=100,\n",
    "        chunksize=1000,\n",
    "        passes=50,\n",
    "        iterations=100\n",
    "    )\n",
    "    print(lda_model.print_topics())\n",
    "else:\n",
    "    print(\"Document term matrix is empty, cannot build LDA model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eddfa73-07c2-4919-b6e6-5368f7759bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity: -20.51739341115975\n",
      "Coherence: 0.6281397952546397\n"
     ]
    }
   ],
   "source": [
    "total_docs = len(doc_term_matrix)\n",
    "if total_docs > 0:\n",
    "    print('\\nPerplexity:', lda_model.log_perplexity(\n",
    "        doc_term_matrix, total_docs=total_docs))\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model,\n",
    "        texts=tokenized_text,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence:', coherence_lda)\n",
    "else:\n",
    "    print(\"No documents to evaluate coherence or perplexity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89df220-21d5-46f1-a1a0-51ff64dc70b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/pgalli/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "if total_docs > 0:\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis_data = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "    vis_data\n",
    "    pyLDAvis.save_html(vis_data, '20_twitter_lda_visualization.html')\n",
    "else:\n",
    "    print(\"No documents for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66601f-16c7-4631-a482-be046a5b44af",
   "metadata": {},
   "source": [
    "## 30 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ac9eee-d556-4cc3-bda6-05d4327e963b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11, '0.159*\"depression\" + 0.092*\"real\" + 0.072*\"big\" + 0.064*\"amp\" + 0.053*\"tomorrow\" + 0.041*\"long\" + 0.031*\"free\" + 0.026*\"number\" + 0.024*\"anxiety\" + 0.024*\"account\"'), (12, '0.126*\"twitter\" + 0.061*\"lot\" + 0.051*\"black\" + 0.044*\"dream\" + 0.040*\"high\" + 0.037*\"rt\" + 0.034*\"song\" + 0.031*\"small\" + 0.030*\"sweet\" + 0.028*\"death\"'), (4, '0.100*\"baby\" + 0.076*\"part\" + 0.073*\"show\" + 0.046*\"social\" + 0.040*\"medium\" + 0.020*\"daily\" + 0.017*\"normal\" + 0.012*\"emotional\" + 0.010*\"ride\" + 0.010*\"pink\"'), (14, '0.067*\"service\" + 0.059*\"positive\" + 0.055*\"body\" + 0.033*\"rest\" + 0.031*\"daddy\" + 0.027*\"thinking\" + 0.025*\"report\" + 0.024*\"personal\" + 0.024*\"quick\" + 0.023*\"move\"'), (18, '0.166*\"girl\" + 0.094*\"nice\" + 0.088*\"talk\" + 0.054*\"end\" + 0.035*\"sex\" + 0.015*\"professional\" + 0.014*\"gorgeous\" + 0.014*\"bag\" + 0.011*\"bunch\" + 0.011*\"awful\"'), (7, '0.087*\"return\" + 0.058*\"job\" + 0.051*\"help\" + 0.036*\"war\" + 0.034*\"tired\" + 0.033*\"h\" + 0.033*\"session\" + 0.025*\"step\" + 0.025*\"rich\" + 0.024*\"pretty\"'), (28, '0.238*\"thank\" + 0.161*\"thing\" + 0.039*\"birthday\" + 0.038*\"wrong\" + 0.037*\"little\" + 0.036*\"strong\" + 0.029*\"car\" + 0.028*\"team\" + 0.020*\"voice\" + 0.019*\"happy\"'), (19, '0.170*\"guy\" + 0.066*\"cool\" + 0.055*\"one\" + 0.052*\"light\" + 0.049*\"least\" + 0.035*\"favorite\" + 0.033*\"dog\" + 0.027*\"news\" + 0.019*\"disorder\" + 0.016*\"follower\"'), (21, '0.307*\"good\" + 0.122*\"day\" + 0.103*\"music\" + 0.080*\"today\" + 0.060*\"happy\" + 0.016*\"human\" + 0.015*\"proud\" + 0.014*\"sick\" + 0.010*\"history\" + 0.009*\"luck\"'), (9, '0.246*\"video\" + 0.087*\"game\" + 0.085*\"fuck\" + 0.074*\"shit\" + 0.037*\"idea\" + 0.030*\"reason\" + 0.025*\"group\" + 0.021*\"support\" + 0.017*\"post\" + 0.015*\"possible\"'), (15, '0.102*\"next\" + 0.097*\"week\" + 0.087*\"word\" + 0.044*\"lol\" + 0.041*\"brain\" + 0.035*\"young\" + 0.034*\"size\" + 0.029*\"check\" + 0.016*\"advice\" + 0.015*\"link\"'), (13, '0.164*\"man\" + 0.150*\"love\" + 0.050*\"ill\" + 0.038*\"true\" + 0.036*\"truth\" + 0.036*\"country\" + 0.036*\"business\" + 0.033*\"company\" + 0.032*\"story\" + 0.029*\"fun\"'), (24, '0.295*\"time\" + 0.053*\"question\" + 0.049*\"funny\" + 0.047*\"white\" + 0.043*\"door\" + 0.024*\"list\" + 0.016*\"bit\" + 0.016*\"moment\" + 0.014*\"decision\" + 0.012*\"drunk\"'), (10, '0.137*\"person\" + 0.107*\"well\" + 0.059*\"second\" + 0.028*\"entire\" + 0.022*\"illness\" + 0.021*\"complete\" + 0.019*\"smell\" + 0.017*\"mental\" + 0.015*\"role\" + 0.013*\"here\"'), (20, '0.070*\"fake\" + 0.064*\"cat\" + 0.061*\"amazing\" + 0.048*\"enough\" + 0.048*\"other\" + 0.022*\"public\" + 0.021*\"serious\" + 0.018*\"buddy\" + 0.018*\"study\" + 0.016*\"busy\"'), (2, '0.153*\"bad\" + 0.096*\"night\" + 0.089*\"tonight\" + 0.045*\"place\" + 0.024*\"election\" + 0.023*\"green\" + 0.020*\"partner\" + 0.017*\"red\" + 0.013*\"band\" + 0.010*\"project\"'), (8, '0.375*\"people\" + 0.062*\"kid\" + 0.047*\"child\" + 0.036*\"school\" + 0.030*\"bitch\" + 0.023*\"self\" + 0.021*\"awesome\" + 0.016*\"college\" + 0.011*\"congrat\" + 0.010*\"husband\"'), (6, '0.125*\"work\" + 0.098*\"first\" + 0.051*\"point\" + 0.042*\"hard\" + 0.041*\"top\" + 0.039*\"minute\" + 0.036*\"line\" + 0.032*\"thought\" + 0.029*\"feeling\" + 0.021*\"suicide\"'), (0, '0.108*\"last\" + 0.101*\"tweet\" + 0.056*\"sleep\" + 0.044*\"law\" + 0.043*\"beautiful\" + 0.039*\"parent\" + 0.036*\"bed\" + 0.034*\"head\" + 0.029*\"office\" + 0.029*\"d\"'), (5, '0.264*\"year\" + 0.097*\"many\" + 0.046*\"health\" + 0.032*\"final\" + 0.032*\"mental\" + 0.023*\"side\" + 0.021*\"use\" + 0.020*\"clothe\" + 0.015*\"figure\" + 0.012*\"hospital\"')]\n"
     ]
    }
   ],
   "source": [
    "if doc_term_matrix:\n",
    "    LDA = gensim.models.ldamodel.LdaModel\n",
    "    lda_model = LDA(\n",
    "        corpus=doc_term_matrix,\n",
    "        id2word=dictionary,\n",
    "        num_topics=30,\n",
    "        random_state=100,\n",
    "        chunksize=1000,\n",
    "        passes=50,\n",
    "        iterations=100\n",
    "    )\n",
    "    print(lda_model.print_topics())\n",
    "else:\n",
    "    print(\"Document term matrix is empty, cannot build LDA model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7796b4-03de-4dd0-9494-0b5258f1c1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity: -27.074841283548224\n",
      "Coherence: 0.646720444535249\n"
     ]
    }
   ],
   "source": [
    "total_docs = len(doc_term_matrix)\n",
    "if total_docs > 0:\n",
    "    print('\\nPerplexity:', lda_model.log_perplexity(\n",
    "        doc_term_matrix, total_docs=total_docs))\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model,\n",
    "        texts=tokenized_text,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence:', coherence_lda)\n",
    "else:\n",
    "    print(\"No documents to evaluate coherence or perplexity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "138db349-0de5-4ded-b6c9-5cf38db3dc68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if total_docs > 0:\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis_data = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "    vis_data\n",
    "    pyLDAvis.save_html(vis_data, '30_twitter_lda_visualization.html')\n",
    "else:\n",
    "    print(\"No documents for visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8171ad-6570-47f3-8410-c8fdc5c9dfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
